{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 4: ¿Superhéroe o Villano? 🦸</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Diego Irarrázaval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
    "\n",
    "- Nombre de alumno 1: Nelson Bruno Moreno Cabañas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** `https://github.com/Bruno-Moreno/LabProgra`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcnsiQMkzAHr"
   },
   "source": [
    "### Indice \n",
    "\n",
    "1. [Temas a tratar](#Temas-a-tratar:)\n",
    "3. [Descripcción del laboratorio](#Descripción-del-laboratorio.)\n",
    "4. [Desarrollo](#Desarrollo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "# Temas a tratar\n",
    "\n",
    "- Clasificación con texto.\n",
    "- Clasificación en `scikit-learn`.\n",
    "- Modelos a través del uso de `pipeline`.\n",
    "- Optimización de modelos usando `GridSearchCV`.\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- Fecha de entrega: 4/06/2021\n",
    "- **Grupos de 2 personas**\n",
    "- **Ausentes** deberán realizar la actividad solos. \n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Prohibidas las copias. \n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "\n",
    "- Aplicar las ventajas que nos ofrece crear un pipeline.\n",
    "- Obtener caracteristicas desde texto.\n",
    "- Crear modelos de clasificación de texto.\n",
    "- Optimizar la clasificación de texto usando wordclouds.\n",
    "- Usar herramientas de visualización de texto como las wordclouds.\n",
    "\n",
    "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhISwri4zAHy"
   },
   "source": [
    "#Importamos librerias utiles 😸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T00:08:16.884674Z",
     "start_time": "2021-03-29T00:08:16.349846Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1623430677131,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "id": "uyc33dKdzAHy",
    "outputId": "0a5f9178-166a-40e7-c4af-18945d518a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: plotly in c:\\users\\bruno\\anaconda3\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\bruno\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (0.24.2)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (0.51.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (0.17.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn) (50.3.1.post20201107)\n",
      "Requirement already satisfied: nltk in c:\\users\\bruno\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librería Core del lab.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Pre-procesamiento\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Clasifación\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Metricas de evaluación\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Librería para plotear\n",
    "!pip install --upgrade plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Proyecciones en baja dimensionalidad: UMAP\n",
    "!pip install umap-learn\n",
    "\n",
    "# Librería para NLP\n",
    "!pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpOTbQcxbSiy"
   },
   "source": [
    "# 1. ¿Quien es Bat Cow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q93vbNS25bM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://static.wikia.nocookie.net/p__/images/a/a2/Bat-Cow.jpg/revision/latest?cb=20180108185037&path-prefix=protagonist\" width=\"350\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnmZfFpxTTYX"
   },
   "source": [
    "En vez de estar oprotunamente desarrollando las tareas y las evaluaciones correspondientes al curso, su profesor de catedra y su auxiliar discuten acerca la alineación del personaje de ficción *Bat-Cow*. \n",
    "\n",
    "El cuerpo docente, no logra ponerse de acuerdo acerca de la alineación del personaje, es decir, si lucha junto a las fuerzas del bien, si neutral a cualquier eventualidad o derechamente es un villano.\n",
    "El auxiliar plantea (de forma superficial) que *Bat-cow* posee una siniestra mirada, común característica de los personajes malvados. \n",
    "Por otra parte, extendiendo las ideas de Rousseau, el profesor (*se cree filósofo... y*) plantea que tal como los humanos no nacen malos, no existe motivo por el cual un rumiante humanizado con superpoderes deba serlo.\n",
    "\n",
    "Sin embargo, ambos concuerdan en es difícil estimar la alineación solo usando los atributos físicos, por lo que creen el análisis debe ser complementado aún más antes de comunicarle los resultados a su estudiantado. Buscando más información, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineación: la historia personal de cada superhéroe o villano.\n",
    "\n",
    "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineación de cada personaje basado en su historia personal.\n",
    "\n",
    "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servirá para entrenar un modelo de clasificación, mientras que el segundo es un dataset con personajes de ficción no etiquetados a predecir (sí, aquí está la misteriosa Batcow).\n",
    "\n",
    "Para iniciar este laboratorio, cargue los dataset señalados y visualice a través de la función `head` los atributos que poseen cada uno de los dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bED3w3tDbSCf"
   },
   "outputs": [],
   "source": [
    "df_comics = pd.read_csv('df_comics.csv')\n",
    "df_comics_no_label = pd.read_csv('comics_no_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4tFPrFA4_O5"
   },
   "source": [
    "## 1.1 Obtención de Features [2 puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_4NF0_V5XZ-"
   },
   "source": [
    "Su primera tarea consiste en generar un vector de características para el atributo `history_text`. En este atributo se presenta una breve descripción de la historia de cada uno de los personajes de ficción presentes en el dataset (si un personaje tiene este atributo nulo, elimínelo). Luego, para obtener características de texto aplique el modelo de conteo `bag of words` de la siguiente forma:\n",
    "\n",
    "- Utilice `CountVectorized` junto al tokenizador (que le proveemos) `LemmaTokenizer`.\n",
    "- Obtenga caracteristicas de los 1-gramas y 2-gramas del texto (ver clase).\n",
    "- Fijar un maximo de 10.000 caracteristicas para el vector de salida.\n",
    "\n",
    "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
    "\n",
    "```python\n",
    "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
    "```\n",
    "\n",
    "No es necesario que obtenga un dataframe en concreto con las características solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
    "\n",
    "**To-Do:**\n",
    "- [X] Obtener a traves de bag of words caracteristicas del resumen de historia de cada personaje.\n",
    "- [X] Aplicar MinMaxScaler sobre los atributos de interes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ay080DunHcOS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Código aquí ####\n",
    "df_comics = df_comics.dropna(subset = [\"history_text\"]) #Eliminamos todos las nan del de history_test\n",
    "df_comics[\"history_text\"].isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ixmI9S6poGDm"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1285x10006 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 343562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplicamos ahora el bag of words\n",
    "vectorizer = CountVectorizer(tokenizer= LemmaTokenizer(), max_features = 10000, ngram_range=(1,2)) \n",
    "\n",
    "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score',\n",
    "                        'durability_score', 'power_score', 'combat_score'] #A estos les aplicamos minmaxscaler\n",
    "\n",
    "preprocessing_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bow',  vectorizer, 'history_text'),\n",
    "        ('MinMaxScaler', MinMaxScaler(), atributos_de_interes)])\n",
    "\n",
    "preprocessing_transformer.fit_transform(df_comics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stHncQ-A-j4I"
   },
   "source": [
    "## 1.2 Diseño de Pipeline y  Primer Entrenamiento [1.5 puntos]\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeMiptpQ_EWb"
   },
   "source": [
    "A continuación, genere un Pipeline con las caracteristicas solicitadas en la sección 1.1, añadiendo un reductor de dimensionalidad llamado `TruncatedSVD()` ajustando el número de componentes en 1000 (este reducto de dimensionalidad es similar al PCA pero funciona para vectores dispersos) y un clasificador `MultinomialNB()` por defecto.  Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde el etiquetado vendrá dado por el atributo `alignment`. Finalmente entrene el modelo y reporte el desempeño con un `classification_report`. ¿ Nos recomendaría predecir la alineación de BatCow con este clasificador?.\n",
    "\n",
    "**Nota:** Debido al desbalance que existe entre las clases, puede ser util aplicar método de [`imbalanced-learn`](https://github.com/scikit-learn-contrib/imbalanced-learn) como RandomOverSampler sobre los datos de entrenamiento. \n",
    "\n",
    "**To-DO:**\n",
    "- [X] Realizar un pipeline con las caracteristicas solicitadas en 1.1,aplicar un reductor de dimensionalidad `TruncatedSVD` y aplicar un clasificador  `MultinomialNB()`.\n",
    "- [X] Entrenar el pipeline.\n",
    "- [X] (Opcional - **0.5 bonus**) Utilizar técnicas de Sampling para balancear los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "_hHpPDooPafy"
   },
   "outputs": [],
   "source": [
    "#### Código aquí ####\n",
    "baseline = Pipeline(steps=[(\"preprocessing\", preprocessing_transformer), \n",
    "                           (\"clf\", MultinomialNB())])\n",
    "y = df_comics[\"alignment\"]\n",
    "X = df_comics.drop(columns = [\"alignment\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=666)\n",
    "\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.53      0.72      0.61       133\n",
      "        Good       0.79      0.68      0.73       255\n",
      "     Neutral       0.29      0.19      0.23        37\n",
      "\n",
      "    accuracy                           0.65       425\n",
      "   macro avg       0.54      0.53      0.52       425\n",
      "weighted avg       0.66      0.65      0.65       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_clf_report = classification_report(y_test, y_pred)\n",
    "print(baseline_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Este es el código cuando se implementa Sampling ###\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "baseline_2 = make_pipeline(preprocessing_transformer,RandomOverSampler(),MultinomialNB()) #Igual que antes pero usamos ROS\n",
    "\n",
    "baseline_2.fit(X_train, y_train)\n",
    "y_pred = baseline_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.52      0.68      0.59       133\n",
      "        Good       0.79      0.66      0.72       255\n",
      "     Neutral       0.24      0.24      0.24        37\n",
      "\n",
      "    accuracy                           0.63       425\n",
      "   macro avg       0.51      0.53      0.51       425\n",
      "weighted avg       0.65      0.63      0.63       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_clf_report = classification_report(y_test, y_pred)\n",
    "print(baseline_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfm7I2B7_rfB"
   },
   "source": [
    "## 1.3 Entrenamiento con Grid Search [2 Puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14siiavzK67p"
   },
   "source": [
    "No conformes con el rendimiento obtenido en la sección 1.2, el cuerpo docente les pide que realicen una búsqueda de grilla de los mejores hiperparámetros utilizando `GridSearchCV`. \n",
    "\n",
    "Para esto, se le solicita que defina al menos 3 configuraciones de hiperparámetros e intente obtener mejores resultados que los obtenidos en la sección anterior. \n",
    "\n",
    "A continuación, un ejemplo de parametros para GridSearch:\n",
    "\n",
    "```python\n",
    "params = [\n",
    "  # esta es la configuración de una busqueda en particular\n",
    "  # con el clasificador classificator1.\n",
    "  # en este caso se entrenará el clasificador 1 con combinaciones de todos los \n",
    "  # parámetros de bow__max_features, bow__ngram_range, clf__n_estimators \n",
    "  # y se seleccionará la mejor combinación.\n",
    "  {\n",
    "  'bow__max_features': [5000, 10000, ...],\n",
    "  'bow__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
    "  ...,\n",
    "  'clf': [classificator1()],\n",
    "  'clf__n_estimators': [200]\n",
    "  },\n",
    "  # esta es la configuración de una busqueda en particular\n",
    "  # con el clasificador classificator2:\n",
    "  {'clf': [classificator2()],\n",
    "   'clf__penalty': ['ovr'],\n",
    "   'clf__multi_class': ['liblinear']\n",
    "  },\n",
    "  # esta es la configuración de una busqueda en particular\n",
    "  # con el clasificador classificator3:\n",
    "  {'clf': [classificator3()]\n",
    "  }\n",
    "             ]\n",
    "```\n",
    "\n",
    "Además, note que puede obtener todos los parámetros configurables de un pipeline invocando sobre este el método `.get_params()`.\n",
    "\n",
    "**Nota:** El GridSearch puede tomar tiempos de búsqueda exorbitantes, por lo que se le recomienda dejar corriendo el código y tomarse un tecito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "oNvHOHELUoIv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB: 0.54302\n",
      "Grid: {'preprocessing__bow__max_features': 9500, 'preprocessing__bow__tokenizer': <__main__.LemmaTokenizer object at 0x000001DEA939AB80>}\n"
     ]
    }
   ],
   "source": [
    "#### Código aquí ####\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk_tokenizer = ToktokTokenizer()\n",
    "snowball = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk_tokenizer.tokenize(text)\n",
    "    stems = [snowball.stem(token) for token in  nltk_tokenizer.tokenize(tokens)]\n",
    "    return stems\n",
    "\n",
    "\n",
    "grid = {\n",
    "    \"preprocessing__bow__max_features\": range(1000, 10000, 1000),\n",
    "    \"preprocessing__bow__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"preprocessing__bow__tokenizer\": [LemmaTokenizer(),tokenize], \n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for g in ParameterGrid(grid):\n",
    "    baseline.set_params(**g)\n",
    "    baseline.fit(X_train, y_train)\n",
    "    y_pred = baseline.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_grid = g\n",
    "\n",
    "print(\"OOB: %0.5f\" % best_score)\n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9TXQK3Hi0Kz"
   },
   "source": [
    "#### 1.3.1 Mejor configuración [0.5]\n",
    "\n",
    "Comente cual fue la mejor configuración obtenida por Grid Search y por qué cree que esta fue la mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzMu7kU_jJsB"
   },
   "source": [
    "> La mejor configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmQUw2aZ_6z2"
   },
   "source": [
    "## 1.4 Predicción del datos sin etiquetado\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj0ERBgTBFWN"
   },
   "source": [
    "Llego el momento de predecir cual es la verdadera alineación de `Batcow`. Para esto, deben escoger el mejor pipeline obtenido en las secciones anteriores y predecir la alineación de todos los datos presentes en `df_comics_no_label`.Luego, anexen las alineaciones obtenidas a su correspondiente columna  del dataframe original (atributo `alignment`) y busquen a los flamantes personajes `Batcow`, `Vergil`, y `Gorilla Girl'. Presente los resultados en un `Dataframe`.\n",
    "\n",
    "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-mizeQZaLUY"
   },
   "outputs": [],
   "source": [
    "#### Código aquí ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BF1beoqllTj"
   },
   "source": [
    "### Wordclouds [Opcional- 0,5] \n",
    "\n",
    "Una buena pero informal forma de comunicar los resultados del trabajo con texto es generar Wordclouds. Este tipo de visualizaciones nos informan de forma gráfica cuales son las palabras más frecuentes según el tamaño de estas al ser posicionadas en un lienzo.\n",
    "<center>\n",
    "<img alt='Ejemplo de una Wordcloud de Starwars' src='https://amueller.github.io/word_cloud/_images/sphx_glr_a_new_hope_001.png' width=400/>\n",
    "\n",
    "Ejemplo de una Wordcloud de Starwars\n",
    "\n",
    "</center>\n",
    "Dicho esto, como equipo docente nos encantaría conocer cuales son las palabras que caracterizan tanto a heroes como neutrales y a villanos y cuales son sus principales diferencias. Por esta razón, les pedimos como última tarea generar una wordcloud con las historias de cada personaje según cada alineamiento (clase). Pueden ocupar el dataset completo para esto. \n",
    "\n",
    "\n",
    "**Nota:** Recuerde eliminar las stopwords. Guías completas para generar las wordclouds, eliminar las stopwords y configurar los parámetros de las nubes creadas pueden ser encontradas en su [documentación oficial](https://amueller.github.io/word_cloud/) y en [datacamp](https://www.datacamp.com/community/tutorials/wordcloud-python).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBdONTJZnLbd"
   },
   "outputs": [],
   "source": [
    "#### Wordcloud para heroes ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-IiZ7PXnLfS"
   },
   "outputs": [],
   "source": [
    "#### Wordcloud para neutrales ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVV1M-osnLnj"
   },
   "outputs": [],
   "source": [
    "#### Wordcloud para villanos ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HljnDhRcoK83"
   },
   "source": [
    "Comente las principales diferencias entre las tres wordclouds.\n",
    "¿Hay palabras que caracterizen a los grupos y que no aparezcan en los otros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tM1jthVRoY93"
   },
   "source": [
    "---> Comente aquí <---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "# Conclusión\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los días de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "enunciado_Laboratorio4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
