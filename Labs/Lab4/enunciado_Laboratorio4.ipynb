{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 4: 쯉uperh칠roe o Villano? 游붲</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Diego Irarr치zaval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
    "\n",
    "- Nombre de alumno 1: Nelson Bruno Moreno Caba침as\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** `https://github.com/Bruno-Moreno/LabProgra`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcnsiQMkzAHr"
   },
   "source": [
    "### Indice \n",
    "\n",
    "1. [Temas a tratar](#Temas-a-tratar:)\n",
    "3. [Descripcci칩n del laboratorio](#Descripci칩n-del-laboratorio.)\n",
    "4. [Desarrollo](#Desarrollo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "# Temas a tratar\n",
    "\n",
    "- Clasificaci칩n con texto.\n",
    "- Clasificaci칩n en `scikit-learn`.\n",
    "- Modelos a trav칠s del uso de `pipeline`.\n",
    "- Optimizaci칩n de modelos usando `GridSearchCV`.\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- Fecha de entrega: 4/06/2021\n",
    "- **Grupos de 2 personas**\n",
    "- **Ausentes** deber치n realizar la actividad solos. \n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
    "- Prohibidas las copias. \n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "\n",
    "- Aplicar las ventajas que nos ofrece crear un pipeline.\n",
    "- Obtener caracteristicas desde texto.\n",
    "- Crear modelos de clasificaci칩n de texto.\n",
    "- Optimizar la clasificaci칩n de texto usando wordclouds.\n",
    "- Usar herramientas de visualizaci칩n de texto como las wordclouds.\n",
    "\n",
    "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhISwri4zAHy"
   },
   "source": [
    "#Importamos librerias utiles 游땾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T00:08:16.884674Z",
     "start_time": "2021-03-29T00:08:16.349846Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1623430677131,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "id": "uyc33dKdzAHy",
    "outputId": "0a5f9178-166a-40e7-c4af-18945d518a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: plotly in c:\\users\\bruno\\anaconda3\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\bruno\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (0.24.2)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (0.51.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (0.17.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn) (50.3.1.post20201107)\n",
      "Requirement already satisfied: nltk in c:\\users\\bruno\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librer칤a Core del lab.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Pre-procesamiento\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Clasifaci칩n\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Metricas de evaluaci칩n\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Librer칤a para plotear\n",
    "!pip install --upgrade plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Proyecciones en baja dimensionalidad: UMAP\n",
    "!pip install umap-learn\n",
    "\n",
    "# Librer칤a para NLP\n",
    "!pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpOTbQcxbSiy"
   },
   "source": [
    "# 1. 쯈uien es Bat Cow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q93vbNS25bM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://static.wikia.nocookie.net/p__/images/a/a2/Bat-Cow.jpg/revision/latest?cb=20180108185037&path-prefix=protagonist\" width=\"350\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnmZfFpxTTYX"
   },
   "source": [
    "En vez de estar oprotunamente desarrollando las tareas y las evaluaciones correspondientes al curso, su profesor de catedra y su auxiliar discuten acerca la alineaci칩n del personaje de ficci칩n *Bat-Cow*. \n",
    "\n",
    "El cuerpo docente, no logra ponerse de acuerdo acerca de la alineaci칩n del personaje, es decir, si lucha junto a las fuerzas del bien, si neutral a cualquier eventualidad o derechamente es un villano.\n",
    "El auxiliar plantea (de forma superficial) que *Bat-cow* posee una siniestra mirada, com칰n caracter칤stica de los personajes malvados. \n",
    "Por otra parte, extendiendo las ideas de Rousseau, el profesor (*se cree fil칩sofo... y*) plantea que tal como los humanos no nacen malos, no existe motivo por el cual un rumiante humanizado con superpoderes deba serlo.\n",
    "\n",
    "Sin embargo, ambos concuerdan en es dif칤cil estimar la alineaci칩n solo usando los atributos f칤sicos, por lo que creen el an치lisis debe ser complementado a칰n m치s antes de comunicarle los resultados a su estudiantado. Buscando m치s informaci칩n, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineaci칩n: la historia personal de cada superh칠roe o villano.\n",
    "\n",
    "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineaci칩n de cada personaje basado en su historia personal.\n",
    "\n",
    "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servir치 para entrenar un modelo de clasificaci칩n, mientras que el segundo es un dataset con personajes de ficci칩n no etiquetados a predecir (s칤, aqu칤 est치 la misteriosa Batcow).\n",
    "\n",
    "Para iniciar este laboratorio, cargue los dataset se침alados y visualice a trav칠s de la funci칩n `head` los atributos que poseen cada uno de los dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bED3w3tDbSCf"
   },
   "outputs": [],
   "source": [
    "df_comics = pd.read_csv('df_comics.csv')\n",
    "df_comics_no_label = pd.read_csv('comics_no_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4tFPrFA4_O5"
   },
   "source": [
    "## 1.1 Obtenci칩n de Features [2 puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_4NF0_V5XZ-"
   },
   "source": [
    "Su primera tarea consiste en generar un vector de caracter칤sticas para el atributo `history_text`. En este atributo se presenta una breve descripci칩n de la historia de cada uno de los personajes de ficci칩n presentes en el dataset (si un personaje tiene este atributo nulo, elim칤nelo). Luego, para obtener caracter칤sticas de texto aplique el modelo de conteo `bag of words` de la siguiente forma:\n",
    "\n",
    "- Utilice `CountVectorized` junto al tokenizador (que le proveemos) `LemmaTokenizer`.\n",
    "- Obtenga caracteristicas de los 1-gramas y 2-gramas del texto (ver clase).\n",
    "- Fijar un maximo de 10.000 caracteristicas para el vector de salida.\n",
    "\n",
    "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
    "\n",
    "```python\n",
    "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
    "```\n",
    "\n",
    "No es necesario que obtenga un dataframe en concreto con las caracter칤sticas solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
    "\n",
    "**To-Do:**\n",
    "- [X] Obtener a traves de bag of words caracteristicas del resumen de historia de cada personaje.\n",
    "- [X] Aplicar MinMaxScaler sobre los atributos de interes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ay080DunHcOS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### C칩digo aqu칤 ####\n",
    "df_comics = df_comics.dropna(subset = [\"history_text\"]) #Eliminamos todos las nan del de history_test\n",
    "df_comics[\"history_text\"].isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ixmI9S6poGDm"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1285x10006 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 343562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplicamos ahora el bag of words\n",
    "vectorizer = CountVectorizer(tokenizer= LemmaTokenizer(), max_features = 10000, ngram_range=(1,2)) \n",
    "\n",
    "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score',\n",
    "                        'durability_score', 'power_score', 'combat_score'] #A estos les aplicamos minmaxscaler\n",
    "\n",
    "preprocessing_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bow',  vectorizer, 'history_text'),\n",
    "        ('MinMaxScaler', MinMaxScaler(), atributos_de_interes)])\n",
    "\n",
    "preprocessing_transformer.fit_transform(df_comics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stHncQ-A-j4I"
   },
   "source": [
    "## 1.2 Dise침o de Pipeline y  Primer Entrenamiento [1.5 puntos]\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeMiptpQ_EWb"
   },
   "source": [
    "A continuaci칩n, genere un Pipeline con las caracteristicas solicitadas en la secci칩n 1.1, a침adiendo un reductor de dimensionalidad llamado `TruncatedSVD()` ajustando el n칰mero de componentes en 1000 (este reducto de dimensionalidad es similar al PCA pero funciona para vectores dispersos) y un clasificador `MultinomialNB()` por defecto.  Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde el etiquetado vendr치 dado por el atributo `alignment`. Finalmente entrene el modelo y reporte el desempe침o con un `classification_report`.  Nos recomendar칤a predecir la alineaci칩n de BatCow con este clasificador?.\n",
    "\n",
    "**Nota:** Debido al desbalance que existe entre las clases, puede ser util aplicar m칠todo de [`imbalanced-learn`](https://github.com/scikit-learn-contrib/imbalanced-learn) como RandomOverSampler sobre los datos de entrenamiento. \n",
    "\n",
    "**To-DO:**\n",
    "- [X] Realizar un pipeline con las caracteristicas solicitadas en 1.1,aplicar un reductor de dimensionalidad `TruncatedSVD` y aplicar un clasificador  `MultinomialNB()`.\n",
    "- [X] Entrenar el pipeline.\n",
    "- [X] (Opcional - **0.5 bonus**) Utilizar t칠cnicas de Sampling para balancear los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "_hHpPDooPafy"
   },
   "outputs": [],
   "source": [
    "#### C칩digo aqu칤 ####\n",
    "baseline = Pipeline(steps=[(\"preprocessing\", preprocessing_transformer), \n",
    "                           (\"clf\", MultinomialNB())])\n",
    "y = df_comics[\"alignment\"]\n",
    "X = df_comics.drop(columns = [\"alignment\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=666)\n",
    "\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.53      0.72      0.61       133\n",
      "        Good       0.79      0.68      0.73       255\n",
      "     Neutral       0.29      0.19      0.23        37\n",
      "\n",
      "    accuracy                           0.65       425\n",
      "   macro avg       0.54      0.53      0.52       425\n",
      "weighted avg       0.66      0.65      0.65       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_clf_report = classification_report(y_test, y_pred)\n",
    "print(baseline_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Este es el c칩digo cuando se implementa Sampling ###\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "baseline_2 = make_pipeline(preprocessing_transformer,RandomOverSampler(),MultinomialNB()) #Igual que antes pero usamos ROS\n",
    "\n",
    "baseline_2.fit(X_train, y_train)\n",
    "y_pred = baseline_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.52      0.68      0.59       133\n",
      "        Good       0.79      0.66      0.72       255\n",
      "     Neutral       0.24      0.24      0.24        37\n",
      "\n",
      "    accuracy                           0.63       425\n",
      "   macro avg       0.51      0.53      0.51       425\n",
      "weighted avg       0.65      0.63      0.63       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_clf_report = classification_report(y_test, y_pred)\n",
    "print(baseline_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfm7I2B7_rfB"
   },
   "source": [
    "## 1.3 Entrenamiento con Grid Search [2 Puntos]\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14siiavzK67p"
   },
   "source": [
    "No conformes con el rendimiento obtenido en la secci칩n 1.2, el cuerpo docente les pide que realicen una b칰squeda de grilla de los mejores hiperpar치metros utilizando `GridSearchCV`. \n",
    "\n",
    "Para esto, se le solicita que defina al menos 3 configuraciones de hiperpar치metros e intente obtener mejores resultados que los obtenidos en la secci칩n anterior. \n",
    "\n",
    "A continuaci칩n, un ejemplo de parametros para GridSearch:\n",
    "\n",
    "```python\n",
    "params = [\n",
    "  # esta es la configuraci칩n de una busqueda en particular\n",
    "  # con el clasificador classificator1.\n",
    "  # en este caso se entrenar치 el clasificador 1 con combinaciones de todos los \n",
    "  # par치metros de bow__max_features, bow__ngram_range, clf__n_estimators \n",
    "  # y se seleccionar치 la mejor combinaci칩n.\n",
    "  {\n",
    "  'bow__max_features': [5000, 10000, ...],\n",
    "  'bow__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
    "  ...,\n",
    "  'clf': [classificator1()],\n",
    "  'clf__n_estimators': [200]\n",
    "  },\n",
    "  # esta es la configuraci칩n de una busqueda en particular\n",
    "  # con el clasificador classificator2:\n",
    "  {'clf': [classificator2()],\n",
    "   'clf__penalty': ['ovr'],\n",
    "   'clf__multi_class': ['liblinear']\n",
    "  },\n",
    "  # esta es la configuraci칩n de una busqueda en particular\n",
    "  # con el clasificador classificator3:\n",
    "  {'clf': [classificator3()]\n",
    "  }\n",
    "             ]\n",
    "```\n",
    "\n",
    "Adem치s, note que puede obtener todos los par치metros configurables de un pipeline invocando sobre este el m칠todo `.get_params()`.\n",
    "\n",
    "**Nota:** El GridSearch puede tomar tiempos de b칰squeda exorbitantes, por lo que se le recomienda dejar corriendo el c칩digo y tomarse un tecito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "oNvHOHELUoIv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB: 0.54302\n",
      "Grid: {'preprocessing__bow__max_features': 9500, 'preprocessing__bow__tokenizer': <__main__.LemmaTokenizer object at 0x000001DEA939AB80>}\n"
     ]
    }
   ],
   "source": [
    "#### C칩digo aqu칤 ####\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk_tokenizer = ToktokTokenizer()\n",
    "snowball = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk_tokenizer.tokenize(text)\n",
    "    stems = [snowball.stem(token) for token in  nltk_tokenizer.tokenize(tokens)]\n",
    "    return stems\n",
    "\n",
    "\n",
    "grid = {\n",
    "    \"preprocessing__bow__max_features\": range(1000, 10000, 1000),\n",
    "    \"preprocessing__bow__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"preprocessing__bow__tokenizer\": [LemmaTokenizer(),tokenize], \n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for g in ParameterGrid(grid):\n",
    "    baseline.set_params(**g)\n",
    "    baseline.fit(X_train, y_train)\n",
    "    y_pred = baseline.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_grid = g\n",
    "\n",
    "print(\"OOB: %0.5f\" % best_score)\n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9TXQK3Hi0Kz"
   },
   "source": [
    "#### 1.3.1 Mejor configuraci칩n [0.5]\n",
    "\n",
    "Comente cual fue la mejor configuraci칩n obtenida por Grid Search y por qu칠 cree que esta fue la mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzMu7kU_jJsB"
   },
   "source": [
    "> La mejor configuraci칩n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmQUw2aZ_6z2"
   },
   "source": [
    "## 1.4 Predicci칩n del datos sin etiquetado\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj0ERBgTBFWN"
   },
   "source": [
    "Llego el momento de predecir cual es la verdadera alineaci칩n de `Batcow`. Para esto, deben escoger el mejor pipeline obtenido en las secciones anteriores y predecir la alineaci칩n de todos los datos presentes en `df_comics_no_label`.Luego, anexen las alineaciones obtenidas a su correspondiente columna  del dataframe original (atributo `alignment`) y busquen a los flamantes personajes `Batcow`, `Vergil`, y `Gorilla Girl'. Presente los resultados en un `Dataframe`.\n",
    "\n",
    "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-mizeQZaLUY"
   },
   "outputs": [],
   "source": [
    "#### C칩digo aqu칤 ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BF1beoqllTj"
   },
   "source": [
    "### Wordclouds [Opcional- 0,5] \n",
    "\n",
    "Una buena pero informal forma de comunicar los resultados del trabajo con texto es generar Wordclouds. Este tipo de visualizaciones nos informan de forma gr치fica cuales son las palabras m치s frecuentes seg칰n el tama침o de estas al ser posicionadas en un lienzo.\n",
    "<center>\n",
    "<img alt='Ejemplo de una Wordcloud de Starwars' src='https://amueller.github.io/word_cloud/_images/sphx_glr_a_new_hope_001.png' width=400/>\n",
    "\n",
    "Ejemplo de una Wordcloud de Starwars\n",
    "\n",
    "</center>\n",
    "Dicho esto, como equipo docente nos encantar칤a conocer cuales son las palabras que caracterizan tanto a heroes como neutrales y a villanos y cuales son sus principales diferencias. Por esta raz칩n, les pedimos como 칰ltima tarea generar una wordcloud con las historias de cada personaje seg칰n cada alineamiento (clase). Pueden ocupar el dataset completo para esto. \n",
    "\n",
    "\n",
    "**Nota:** Recuerde eliminar las stopwords. Gu칤as completas para generar las wordclouds, eliminar las stopwords y configurar los par치metros de las nubes creadas pueden ser encontradas en su [documentaci칩n oficial](https://amueller.github.io/word_cloud/) y en [datacamp](https://www.datacamp.com/community/tutorials/wordcloud-python).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBdONTJZnLbd"
   },
   "outputs": [],
   "source": [
    "#### Wordcloud para heroes ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-IiZ7PXnLfS"
   },
   "outputs": [],
   "source": [
    "#### Wordcloud para neutrales ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVV1M-osnLnj"
   },
   "outputs": [],
   "source": [
    "#### Wordcloud para villanos ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HljnDhRcoK83"
   },
   "source": [
    "Comente las principales diferencias entre las tres wordclouds.\n",
    "쮿ay palabras que caracterizen a los grupos y que no aparezcan en los otros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tM1jthVRoY93"
   },
   "source": [
    "---> Comente aqu칤 <---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "# Conclusi칩n\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los d칤as de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "enunciado_Laboratorio4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
