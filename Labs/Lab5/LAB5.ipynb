{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 5: Benchmark Bayesiano 🧮</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Diego Irarrázaval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
    "\n",
    "- Nombre de alumno 1: Nelson Moreno Cabañas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** `https://github.com/Bruno-Moreno/LabProgra`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcnsiQMkzAHr"
   },
   "source": [
    "### Indice \n",
    "\n",
    "1. [Temas a tratar](#Temas-a-tratar:)\n",
    "3. [Descripcción del laboratorio](#Descripción-del-laboratorio.)\n",
    "4. [Objetivos principales del laboratorio](#Objetivos-principales-del-laboratorio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "# Temas a tratar\n",
    "\n",
    "- Optimización de Código en Python.\n",
    "- Utilización de librerías para medir el tiempo de ejecución de funciones.\n",
    "- Métodos para optimizar el rendimiento de las funciones.\n",
    "\n",
    "# Reglas:\n",
    "\n",
    "- Fecha de entrega: 4/06/2021\n",
    "- **Grupos de 2 personas**\n",
    "- **Ausentes** deberán realizar la actividad solos. \n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Prohibidas las copias. \n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "# Objetivos principales del laboratorio\n",
    "\n",
    "- Obtener datos desde Reddit y visualizar cuales post son más probables que sean puntuados positivamente.\n",
    "- Aplicar un atajo bayesiano para obtener la mean posterior de datos.\n",
    "- Optimizar a través de librerías funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhISwri4zAHy"
   },
   "source": [
    "#Importamos librerias utiles 😸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cO7AQ9ciQ59U"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install praw\n",
    "!pip install line_profiler\n",
    "!pip install memory_profiler\n",
    "import sys\n",
    "import praw\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import plotly.express as px\n",
    "from functools import lru_cache\n",
    "from IPython.core.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpOTbQcxbSiy"
   },
   "source": [
    "# 1. Recomendando Posts de Subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q93vbNS25bM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://styles.redditmedia.com/t5_2rer8/styles/bannerBackgroundImage_6o2td1zc54671.jpg?width=4000&format=pjpg&s=600bcf8560dff264f1cc7c0785ba5f6d529e0c28\" width=\"10000\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnmZfFpxTTYX"
   },
   "source": [
    "Unos intrépidos alumnos del curso, quienes frecuentemente participan en subreddits y foros de reviews, se preguntan lo siguiente: ¿Podremos confiar que un post es bueno, si este tiene solamente 1 o 3 votos positivos?. los compañeros, creen que esto claramente no representa una opinión general, ya que estamos mucho menos seguros acerca de la verdadera proporción de votos a favor de los comentarios con pocos datos. ¿Pero cómo podemos obtener una representación más creíble para este problema?.\n",
    "\n",
    "Lo señalado forma parte de un problema Bayesiano, donde a través del cálculo de la posterior se puede conocer que tan probable es que un post sea bueno. Para efectos de este laboratorio, no se exige un conocimiento previo para resolver este problema, simplemente se deberá aplicar las ecuaciones presentadas más adelante (De igual forma si quedan interesados sobre el tema se les invita a tomar el ramo [CC6104](https://github.com/dccuchile/CC6104))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdbrb3AMi6EF"
   },
   "source": [
    "## 1.1 Obtención de Subrredits y Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI-IRspcjPee"
   },
   "source": [
    "Para estudiar que tan probable es que un post sea positivo se comenzará cargando datos reales del subreddit chile desde reddit (si usted desea puede cambiar el subreddit a uno de su gusto). Para esto le proponemos la utilización de la función que aparece mas abajo, la que presenta un usuario ya creado por el equipo docente. Dese un tiempo para entender que hace cada parte de la función, visualizando que se obtiene de estas.\n",
    "\n",
    "Revisada la función, utilice un **perfilador** para monitorear el tiempo y memoria que les toma a las subfunciones ser ejecutadas (por linea de código, vean las clases). Señale cuales son los procesos que mas tiempo consumen en la ejecución del Código, comentando si es posible mejorar el desempeño de la función.\n",
    "\n",
    "**TO-DO:**\n",
    "- [X] Estudiar la función propuesta por el equipo docente.\n",
    "- [X] Estudiar los tiempos de ejecución del Código a través de un perfilador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "R4PQbceVPJzh"
   },
   "outputs": [],
   "source": [
    "def praw_reddit(nombre_subreddit = 'chile', n_hot = 1000):\n",
    "    reddit = praw.Reddit(client_id='-w2hyFINxZ8T3g',\n",
    "                     client_secret='zGPCI4s3g6Ic6AsRi7vIpP0NoxbFdw',\n",
    "                     password='ClasesMDS7202',\n",
    "                     user_agent='Clases',\n",
    "                     username='DocenciaDataScience', check_for_async=False)\n",
    "        \n",
    "    subreddit  = reddit.subreddit(nombre_subreddit)\n",
    "\n",
    "    votes, post, url = {}, {}, {}\n",
    "    top_submissions = list(subreddit.hot(limit = n_hot))\n",
    "    for it, top_n in enumerate(range(50, len(top_submissions),50)):\n",
    "        top_n_submissions = top_submissions[:top_n]\n",
    "        \n",
    "    upvotes, downvotes, url[it], post[it] = [], [], [], []\n",
    "\n",
    "    for submission in top_n_submissions:\n",
    "        try:\n",
    "            ratio = submission.upvote_ratio\n",
    "            ups = int(round((ratio*submission.score)/(2*ratio - 1)) if ratio != 0.5 else round(submission.score/2))\n",
    "            upvotes.append(ups)\n",
    "            downvotes.append(ups - submission.score)\n",
    "            post[it].append(submission.title)\n",
    "            url[it].append(submission.url)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    votes[it] = np.array([upvotes, downvotes]).T\n",
    "    return votes, post, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8JZisW6fm0RB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "#### Código Aquí ####\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f praw_reddit praw_reddit() #Por alguna razón no se imprime y lo muestra aparte en mi jupypter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 147.60 MiB, increment: 10.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit praw_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-diI_GpXmzqS"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gdqQBi1m_cu"
   },
   "source": [
    "> Según el perfilador, el proceso que más toma es la linea top_submissions pues el método subreddit.hot recolecta los comentarios con más votaciones (entre todos los comentarios) y posiblemente los ordene lo que evidentemente toma un gran tiempo, la forma de optimizar esto vendría siendo una estructura de datos predefinida en reddit que facilite este proceso o bien una implementación en algún lenguaje más rápido.\n",
    "La siguiente linea que toma bastante tiempo es praw.reddit() que accede al usuario de reddit correspondiente pero a priori no se conocen forma de optimizar este proceso salvo que tengamos acceso al método en particular. \n",
    "Por último la linea ups = ... es otra que toma bastante tiempo pero corresponden simplemente a operaciones matemáticas.\n",
    "\n",
    "> Se puede observar además la cantidad de memoria utilizada y los incrementos en la linea %memit, vemos que la cantidad de memoria peak es bastante alta pues en algún momento se deben guardar todos los comentarios del subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNDS2OpFnMnH"
   },
   "source": [
    "## 1.2 Análisis de Tiempo con Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3nsxCbAna4t"
   },
   "source": [
    "Sin duda, un factor clave en la mejora del tiempo de ejecución de una aplicación es el uso eficiente de la memoria. Por lo que es importante, que ustedes respondan las siguientes preguntas:\n",
    "1.\t¿Qué es la memoria cache y a que se refiere las siglas LRU?\n",
    "2.\t¿Cuáles son los costos que tiene la aplicación de técnicas de Caching?\n",
    "3. ¿Cuál es la consecuencía de ocupar caching en la función anterior?.\n",
    "\n",
    "Respondidas las preguntas, se le solicita que aplique alguna técnica de caching para mejorar el desempeño de la función `praw_reddit`. Para esto compare solo el tiempo de ejecución del algoritmo con y sin caching, señalando el tiempo total de ejecución y el tiempo promedio que le toma ejecutar cada loop a la función. Con lo anterior, ¿es posible visualizar mejoras en este caso?.\n",
    "\n",
    "\n",
    "**TO-DO:**\n",
    "- [X] Responder preguntas.\n",
    "- [X] Mejorar el código con cache.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbQPpvYorOAF"
   },
   "source": [
    "**Respuestas Teóricas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKfLXDs_rO-w"
   },
   "source": [
    "> 1. La memoria cache es la que permite almacenar en el disco o RAM los resultados de procesos anteriores con el fin de ser utilizados más adelante, las siglas LRU vienen de Least Recently Used y quiere decir que se almacenaran en cache los procesos por orden de ejecución.\n",
    "> 2. El problema de las técnicas de Caching es que aumentamos el uso de memoria, lo cual puede traer problemas pues la memoria de nuestro hardware es limitada, o bien, de lento acceso.\n",
    "> 3. Como vimos en la memoria utilizada, su uso ya es de 147MB y utilizar técnicas de caching podría aumentar considerablemente el uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "X0u4WU11rLJd"
   },
   "outputs": [],
   "source": [
    "#### Código para optimizar la función praw ####\n",
    "@lru_cache\n",
    "def praw_reddit(nombre_subreddit = 'chile', n_hot = 1000):\n",
    "    reddit = praw.Reddit(client_id='-w2hyFINxZ8T3g',\n",
    "                     client_secret='zGPCI4s3g6Ic6AsRi7vIpP0NoxbFdw',\n",
    "                     password='ClasesMDS7202',\n",
    "                     user_agent='Clases',\n",
    "                     username='DocenciaDataScience', check_for_async=False)\n",
    "        \n",
    "    subreddit  = reddit.subreddit(nombre_subreddit)\n",
    "\n",
    "    votes, post, url = {}, {}, {}\n",
    "    top_submissions = list(subreddit.hot(limit = n_hot))\n",
    "    for it, top_n in enumerate(range(50, len(top_submissions),50)):\n",
    "        top_n_submissions = top_submissions[:top_n]\n",
    "        \n",
    "    upvotes, downvotes, url[it], post[it] = [], [], [], []\n",
    "\n",
    "    for submission in top_n_submissions:\n",
    "        try:\n",
    "            ratio = submission.upvote_ratio\n",
    "            ups = int(round((ratio*submission.score)/(2*ratio - 1)) if ratio != 0.5 else round(submission.score/2))\n",
    "            upvotes.append(ups)\n",
    "            downvotes.append(ups - submission.score)\n",
    "            post[it].append(submission.title)\n",
    "            url[it].append(submission.url)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    votes[it] = np.array([upvotes, downvotes]).T\n",
    "    return votes, post, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.50 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "386 ns ± 455 ns per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "praw_reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.6 ns ± 0.138 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "praw_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vemos claramente la diferencia en los tiempos de ejecución al guardarlos en la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pS26u-trdg6"
   },
   "source": [
    "## 1.3 Obtención de Mean Posterior y Standard Error\n",
    "\n",
    "Una forma de obtener la mean posterior y el Standard Error de los datos de reddit es aplicando un atajo de inferencia Bayesiana. Este atajo se define de la siguiente forma:\n",
    "\n",
    "Sea **u** los votos positivos y **d** los votos negativos del subreddit, tendremos que:\n",
    "\n",
    "$$a = 1+u$$\n",
    "$$b = 1+d$$\n",
    "\n",
    "$$\\sigma= 1.65\\sqrt(\\dfrac{ab}{(a + b)^2(a + b + 1)})$$\n",
    "\n",
    "$$\\mu = \\dfrac{a}{a+b}$$\n",
    "\n",
    "Donde $\\mu$ es la mean posterior y $\\sigma$ el standard error.\n",
    "\n",
    "Con lo anterior, genere dos funciones que tengan como salida $\\mu$ y $\\sigma$ de acuerdo a las ecuaciones señaladas. La primera función, deberá ser construida sin el uso de numpy, aplicando for y aplicando comandos nativos de Python. Por otro lado, deberá generar una segunda función con el uso exclusivo de numpy. **OJO** que las funciones deben tener como entrada solo un elemento del diccionario votes (por ejemplo `votes[1]`), por lo que estas no deben tener como entrada el conjunto completo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110391, 6085)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes, post, url = praw_reddit()\n",
    "votos = votes[18]\n",
    "posteo = votes[18]\n",
    "np.sum(votos[:, 0]), np.sum(votos[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "ahzpJ-Sk0DOD"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "def intervalos(votos_positivos, votos_negativos):\n",
    "    suma_positivos = 0\n",
    "    suma_negativos = 0\n",
    "    for i in range(len(votos_positivos)):\n",
    "        suma_positivos += votos_positivos[i]\n",
    "        suma_negativos += votos_negativos[i]\n",
    "    a = int(1+suma_positivos) #para que sean considerados long\n",
    "    b = int(1+suma_negativos) #para que sean considerados long\n",
    "    mu = a/(a+b)\n",
    "    sigma = 1.65 * math.sqrt(a*b/(((a+b)**2)*(a+b+1)))\n",
    "    return mu,sigma\n",
    "    \n",
    "    \n",
    "\n",
    "def intervalos_numpy(votos_positivos, votos_negativos):\n",
    "    suma_positivos = np.sum(votos_positivos)\n",
    "    suma_negativos = np.sum(votos_negativos)\n",
    "    a = int(1+suma_positivos) #para que sean considerados long\n",
    "    b = int(1+suma_negativos) #para que sean considerados long\n",
    "    mu = a/(a+b)\n",
    "    sigma = 1.65 * math.sqrt(a*b/(((a+b)**2)*(a+b+1)))\n",
    "    return mu,sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervalos(votos[:, 0], votos[:, 1]) == intervalos_numpy(votos[:, 0], votos[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhHhiTRYwpGu"
   },
   "source": [
    "## 1.4 Comparación de rendimiento\n",
    "\n",
    "Creadas las funciones de la sección 1.3, de forma iterativa compare los diferentes batches de datos que contiene el diccionario `votes`. Para esto genere un gráfico utilizando plotly, donde se pueda observar las diferencias de tiempo que toma ejecutar las diferentes cantidades de datos. ¿es posible observar una diferencia? ¿a qué se deberá esto?.\n",
    "\n",
    "Aplique el compilador **Numba** sobre las funciones 1.3 y compare el tiempo de ejecución con los obtenidos sin el compilador. Grafique estos tiempos y observe comente los desempeños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b02IokToxPpO"
   },
   "outputs": [],
   "source": [
    "###### Código Aquí ######\n",
    "\n",
    "def intevalos_JIT(votos_positivos, votos negativos):\n",
    "  pass \n",
    "\n",
    "def intevalos_numpy_JIT(votos_positivos, votos negativos):\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DljdJw8m0gYC"
   },
   "source": [
    "## 1.5 Plot de Resultados Bayesianos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQAxOM5D08Hl"
   },
   "source": [
    "Llego la hora de visualizar los resultados obtenidos, para esto solo ejecute las siguientes celdas y observe lo que sucede :3. ¿Qué logra observar de los resultados?, ¿La solución resulta trivial?\n",
    "\n",
    "En esta sección esperamos que solo comenten con lo que logran visualizar de los dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1624645025761,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "id": "N5E2mNYXaafI",
    "outputId": "36f8a568-fb8d-4a2b-ff8e-651f206fbe53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower bounds aproximados:\n",
      "\n",
      "Top 20 post ordenador por el limite inferior:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#votos = votes[len(votes)-1]  esta no funciona\n",
    "#posteo = post[len(post)-1] esta no funciona\n",
    "votos = votes[18]\n",
    "posteo = post[18]\n",
    "print(\"lower bounds aproximados:\")\n",
    "posterior_mean, std_err = intervalos_numpy(votos[:, 0], votos[:, 1])\n",
    "lb = posterior_mean - std_err\n",
    "print(\"\\nTop 20 post ordenador por el limite inferior:\\n\")\n",
    "order = np.argsort(-lb)\n",
    "vote_post = {'Votos (+)':votos[order[:20], 0], 'Votos (-)':votos[order[:20], 1] ,'Post':np.array(posteo)[order[:20]], 'url': np.array(url[18])[order[:20]]}\n",
    "df = pd.DataFrame(data=vote_post)\n",
    "ordered_post = df.Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1753,
     "status": "ok",
     "timestamp": 1624645046704,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "id": "ZZ-AY2XTuLa_",
    "outputId": "5e363e6a-701b-4c2e-eb51-f082a8c6d492"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-f8cd58ca3582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mr_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_dic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mposterior_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std_err'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstd_err\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'post'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mordered_post\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m fig = px.scatter(df, x=\"mean\", y=\"post\",\n\u001b[0;32m      5\u001b[0m                  error_x=\"std_err\")\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "r_order = order[::-1][-20:]\n",
    "data_dic = {'mean':posterior_mean[r_order], 'std_err':std_err[r_order], 'post':ordered_post[::-1]}\n",
    "df = pd.DataFrame(data=data_dic)\n",
    "fig = px.scatter(df, x=\"mean\", y=\"post\",\n",
    "                 error_x=\"std_err\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szOjXLKA1Rif"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F83QdD61Pd1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "# Conclusión\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los días de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "enunciado_Laboratorio5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
