{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 5: Benchmark Bayesiano 游빑</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Diego Irarr치zaval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
    "\n",
    "- Nombre de alumno 1: Nelson Moreno Caba침as\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** `https://github.com/Bruno-Moreno/LabProgra`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcnsiQMkzAHr"
   },
   "source": [
    "### Indice \n",
    "\n",
    "1. [Temas a tratar](#Temas-a-tratar:)\n",
    "3. [Descripcci칩n del laboratorio](#Descripci칩n-del-laboratorio.)\n",
    "4. [Objetivos principales del laboratorio](#Objetivos-principales-del-laboratorio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "# Temas a tratar\n",
    "\n",
    "- Optimizaci칩n de C칩digo en Python.\n",
    "- Utilizaci칩n de librer칤as para medir el tiempo de ejecuci칩n de funciones.\n",
    "- M칠todos para optimizar el rendimiento de las funciones.\n",
    "\n",
    "# Reglas:\n",
    "\n",
    "- Fecha de entrega: 4/06/2021\n",
    "- **Grupos de 2 personas**\n",
    "- **Ausentes** deber치n realizar la actividad solos. \n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
    "- Prohibidas las copias. \n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "# Objetivos principales del laboratorio\n",
    "\n",
    "- Obtener datos desde Reddit y visualizar cuales post son m치s probables que sean puntuados positivamente.\n",
    "- Aplicar un atajo bayesiano para obtener la mean posterior de datos.\n",
    "- Optimizar a trav칠s de librer칤as funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhISwri4zAHy"
   },
   "source": [
    "#Importamos librerias utiles 游땾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cO7AQ9ciQ59U"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install praw\n",
    "!pip install line_profiler\n",
    "!pip install memory_profiler\n",
    "import sys\n",
    "import praw\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import plotly.express as px\n",
    "from functools import lru_cache\n",
    "from IPython.core.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpOTbQcxbSiy"
   },
   "source": [
    "# 1. Recomendando Posts de Subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q93vbNS25bM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://styles.redditmedia.com/t5_2rer8/styles/bannerBackgroundImage_6o2td1zc54671.jpg?width=4000&format=pjpg&s=600bcf8560dff264f1cc7c0785ba5f6d529e0c28\" width=\"10000\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnmZfFpxTTYX"
   },
   "source": [
    "Unos intr칠pidos alumnos del curso, quienes frecuentemente participan en subreddits y foros de reviews, se preguntan lo siguiente: 쯇odremos confiar que un post es bueno, si este tiene solamente 1 o 3 votos positivos?. los compa침eros, creen que esto claramente no representa una opini칩n general, ya que estamos mucho menos seguros acerca de la verdadera proporci칩n de votos a favor de los comentarios con pocos datos. 쯇ero c칩mo podemos obtener una representaci칩n m치s cre칤ble para este problema?.\n",
    "\n",
    "Lo se침alado forma parte de un problema Bayesiano, donde a trav칠s del c치lculo de la posterior se puede conocer que tan probable es que un post sea bueno. Para efectos de este laboratorio, no se exige un conocimiento previo para resolver este problema, simplemente se deber치 aplicar las ecuaciones presentadas m치s adelante (De igual forma si quedan interesados sobre el tema se les invita a tomar el ramo [CC6104](https://github.com/dccuchile/CC6104))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdbrb3AMi6EF"
   },
   "source": [
    "## 1.1 Obtenci칩n de Subrredits y An치lisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI-IRspcjPee"
   },
   "source": [
    "Para estudiar que tan probable es que un post sea positivo se comenzar치 cargando datos reales del subreddit chile desde reddit (si usted desea puede cambiar el subreddit a uno de su gusto). Para esto le proponemos la utilizaci칩n de la funci칩n que aparece mas abajo, la que presenta un usuario ya creado por el equipo docente. Dese un tiempo para entender que hace cada parte de la funci칩n, visualizando que se obtiene de estas.\n",
    "\n",
    "Revisada la funci칩n, utilice un **perfilador** para monitorear el tiempo y memoria que les toma a las subfunciones ser ejecutadas (por linea de c칩digo, vean las clases). Se침ale cuales son los procesos que mas tiempo consumen en la ejecuci칩n del C칩digo, comentando si es posible mejorar el desempe침o de la funci칩n.\n",
    "\n",
    "**TO-DO:**\n",
    "- [X] Estudiar la funci칩n propuesta por el equipo docente.\n",
    "- [X] Estudiar los tiempos de ejecuci칩n del C칩digo a trav칠s de un perfilador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "R4PQbceVPJzh"
   },
   "outputs": [],
   "source": [
    "def praw_reddit(nombre_subreddit = 'chile', n_hot = 1000):\n",
    "    reddit = praw.Reddit(client_id='-w2hyFINxZ8T3g',\n",
    "                     client_secret='zGPCI4s3g6Ic6AsRi7vIpP0NoxbFdw',\n",
    "                     password='ClasesMDS7202',\n",
    "                     user_agent='Clases',\n",
    "                     username='DocenciaDataScience', check_for_async=False)\n",
    "        \n",
    "    subreddit  = reddit.subreddit(nombre_subreddit)\n",
    "\n",
    "    votes, post, url = {}, {}, {}\n",
    "    top_submissions = list(subreddit.hot(limit = n_hot))\n",
    "    for it, top_n in enumerate(range(50, len(top_submissions),50)):\n",
    "        top_n_submissions = top_submissions[:top_n]\n",
    "        \n",
    "    upvotes, downvotes, url[it], post[it] = [], [], [], []\n",
    "\n",
    "    for submission in top_n_submissions:\n",
    "        try:\n",
    "            ratio = submission.upvote_ratio\n",
    "            ups = int(round((ratio*submission.score)/(2*ratio - 1)) if ratio != 0.5 else round(submission.score/2))\n",
    "            upvotes.append(ups)\n",
    "            downvotes.append(ups - submission.score)\n",
    "            post[it].append(submission.title)\n",
    "            url[it].append(submission.url)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    votes[it] = np.array([upvotes, downvotes]).T\n",
    "    return votes, post, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8JZisW6fm0RB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "#### C칩digo Aqu칤 ####\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f praw_reddit praw_reddit() #Por alguna raz칩n no se imprime y lo muestra aparte en mi jupypter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 147.60 MiB, increment: 10.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit praw_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-diI_GpXmzqS"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gdqQBi1m_cu"
   },
   "source": [
    "> Seg칰n el perfilador, el proceso que m치s toma es la linea top_submissions pues el m칠todo subreddit.hot recolecta los comentarios con m치s votaciones (entre todos los comentarios) y posiblemente los ordene lo que evidentemente toma un gran tiempo, la forma de optimizar esto vendr칤a siendo una estructura de datos predefinida en reddit que facilite este proceso o bien una implementaci칩n en alg칰n lenguaje m치s r치pido.\n",
    "La siguiente linea que toma bastante tiempo es praw.reddit() que accede al usuario de reddit correspondiente pero a priori no se conocen forma de optimizar este proceso salvo que tengamos acceso al m칠todo en particular. \n",
    "Por 칰ltimo la linea ups = ... es otra que toma bastante tiempo pero corresponden simplemente a operaciones matem치ticas.\n",
    "\n",
    "> Se puede observar adem치s la cantidad de memoria utilizada y los incrementos en la linea %memit, vemos que la cantidad de memoria peak es bastante alta pues en alg칰n momento se deben guardar todos los comentarios del subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNDS2OpFnMnH"
   },
   "source": [
    "## 1.2 An치lisis de Tiempo con Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3nsxCbAna4t"
   },
   "source": [
    "Sin duda, un factor clave en la mejora del tiempo de ejecuci칩n de una aplicaci칩n es el uso eficiente de la memoria. Por lo que es importante, que ustedes respondan las siguientes preguntas:\n",
    "1.\t쯈u칠 es la memoria cache y a que se refiere las siglas LRU?\n",
    "2.\t쮺u치les son los costos que tiene la aplicaci칩n de t칠cnicas de Caching?\n",
    "3. 쮺u치l es la consecuenc칤a de ocupar caching en la funci칩n anterior?.\n",
    "\n",
    "Respondidas las preguntas, se le solicita que aplique alguna t칠cnica de caching para mejorar el desempe침o de la funci칩n `praw_reddit`. Para esto compare solo el tiempo de ejecuci칩n del algoritmo con y sin caching, se침alando el tiempo total de ejecuci칩n y el tiempo promedio que le toma ejecutar cada loop a la funci칩n. Con lo anterior, 쯘s posible visualizar mejoras en este caso?.\n",
    "\n",
    "\n",
    "**TO-DO:**\n",
    "- [X] Responder preguntas.\n",
    "- [X] Mejorar el c칩digo con cache.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbQPpvYorOAF"
   },
   "source": [
    "**Respuestas Te칩ricas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKfLXDs_rO-w"
   },
   "source": [
    "> 1. La memoria cache es la que permite almacenar en el disco o RAM los resultados de procesos anteriores con el fin de ser utilizados m치s adelante, las siglas LRU vienen de Least Recently Used y quiere decir que se almacenaran en cache los procesos por orden de ejecuci칩n.\n",
    "> 2. El problema de las t칠cnicas de Caching es que aumentamos el uso de memoria, lo cual puede traer problemas pues la memoria de nuestro hardware es limitada, o bien, de lento acceso.\n",
    "> 3. Como vimos en la memoria utilizada, su uso ya es de 147MB y utilizar t칠cnicas de caching podr칤a aumentar considerablemente el uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "X0u4WU11rLJd"
   },
   "outputs": [],
   "source": [
    "#### C칩digo para optimizar la funci칩n praw ####\n",
    "@lru_cache\n",
    "def praw_reddit(nombre_subreddit = 'chile', n_hot = 1000):\n",
    "    reddit = praw.Reddit(client_id='-w2hyFINxZ8T3g',\n",
    "                     client_secret='zGPCI4s3g6Ic6AsRi7vIpP0NoxbFdw',\n",
    "                     password='ClasesMDS7202',\n",
    "                     user_agent='Clases',\n",
    "                     username='DocenciaDataScience', check_for_async=False)\n",
    "        \n",
    "    subreddit  = reddit.subreddit(nombre_subreddit)\n",
    "\n",
    "    votes, post, url = {}, {}, {}\n",
    "    top_submissions = list(subreddit.hot(limit = n_hot))\n",
    "    for it, top_n in enumerate(range(50, len(top_submissions),50)):\n",
    "        top_n_submissions = top_submissions[:top_n]\n",
    "        \n",
    "    upvotes, downvotes, url[it], post[it] = [], [], [], []\n",
    "\n",
    "    for submission in top_n_submissions:\n",
    "        try:\n",
    "            ratio = submission.upvote_ratio\n",
    "            ups = int(round((ratio*submission.score)/(2*ratio - 1)) if ratio != 0.5 else round(submission.score/2))\n",
    "            upvotes.append(ups)\n",
    "            downvotes.append(ups - submission.score)\n",
    "            post[it].append(submission.title)\n",
    "            url[it].append(submission.url)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    votes[it] = np.array([upvotes, downvotes]).T\n",
    "    return votes, post, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.50 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "386 ns 췀 455 ns per loop (mean 췀 std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "praw_reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.6 ns 췀 0.138 ns per loop (mean 췀 std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "praw_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vemos claramente la diferencia en los tiempos de ejecuci칩n al guardarlos en la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pS26u-trdg6"
   },
   "source": [
    "## 1.3 Obtenci칩n de Mean Posterior y Standard Error\n",
    "\n",
    "Una forma de obtener la mean posterior y el Standard Error de los datos de reddit es aplicando un atajo de inferencia Bayesiana. Este atajo se define de la siguiente forma:\n",
    "\n",
    "Sea **u** los votos positivos y **d** los votos negativos del subreddit, tendremos que:\n",
    "\n",
    "$$a = 1+u$$\n",
    "$$b = 1+d$$\n",
    "\n",
    "$$\\sigma= 1.65\\sqrt(\\dfrac{ab}{(a + b)^2(a + b + 1)})$$\n",
    "\n",
    "$$\\mu = \\dfrac{a}{a+b}$$\n",
    "\n",
    "Donde $\\mu$ es la mean posterior y $\\sigma$ el standard error.\n",
    "\n",
    "Con lo anterior, genere dos funciones que tengan como salida $\\mu$ y $\\sigma$ de acuerdo a las ecuaciones se침aladas. La primera funci칩n, deber치 ser construida sin el uso de numpy, aplicando for y aplicando comandos nativos de Python. Por otro lado, deber치 generar una segunda funci칩n con el uso exclusivo de numpy. **OJO** que las funciones deben tener como entrada solo un elemento del diccionario votes (por ejemplo `votes[1]`), por lo que estas no deben tener como entrada el conjunto completo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110391, 6085)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes, post, url = praw_reddit()\n",
    "votos = votes[18]\n",
    "posteo = votes[18]\n",
    "np.sum(votos[:, 0]), np.sum(votos[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "ahzpJ-Sk0DOD"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "def intervalos(votos_positivos, votos_negativos):\n",
    "    suma_positivos = 0\n",
    "    suma_negativos = 0\n",
    "    for i in range(len(votos_positivos)):\n",
    "        suma_positivos += votos_positivos[i]\n",
    "        suma_negativos += votos_negativos[i]\n",
    "    a = int(1+suma_positivos) #para que sean considerados long\n",
    "    b = int(1+suma_negativos) #para que sean considerados long\n",
    "    mu = a/(a+b)\n",
    "    sigma = 1.65 * math.sqrt(a*b/(((a+b)**2)*(a+b+1)))\n",
    "    return mu,sigma\n",
    "    \n",
    "    \n",
    "\n",
    "def intervalos_numpy(votos_positivos, votos_negativos):\n",
    "    suma_positivos = np.sum(votos_positivos)\n",
    "    suma_negativos = np.sum(votos_negativos)\n",
    "    a = int(1+suma_positivos) #para que sean considerados long\n",
    "    b = int(1+suma_negativos) #para que sean considerados long\n",
    "    mu = a/(a+b)\n",
    "    sigma = 1.65 * math.sqrt(a*b/(((a+b)**2)*(a+b+1)))\n",
    "    return mu,sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervalos(votos[:, 0], votos[:, 1]) == intervalos_numpy(votos[:, 0], votos[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhHhiTRYwpGu"
   },
   "source": [
    "## 1.4 Comparaci칩n de rendimiento\n",
    "\n",
    "Creadas las funciones de la secci칩n 1.3, de forma iterativa compare los diferentes batches de datos que contiene el diccionario `votes`. Para esto genere un gr치fico utilizando plotly, donde se pueda observar las diferencias de tiempo que toma ejecutar las diferentes cantidades de datos. 쯘s posible observar una diferencia? 쯔 qu칠 se deber치 esto?.\n",
    "\n",
    "Aplique el compilador **Numba** sobre las funciones 1.3 y compare el tiempo de ejecuci칩n con los obtenidos sin el compilador. Grafique estos tiempos y observe comente los desempe침os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b02IokToxPpO"
   },
   "outputs": [],
   "source": [
    "###### C칩digo Aqu칤 ######\n",
    "\n",
    "def intevalos_JIT(votos_positivos, votos negativos):\n",
    "  pass \n",
    "\n",
    "def intevalos_numpy_JIT(votos_positivos, votos negativos):\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DljdJw8m0gYC"
   },
   "source": [
    "## 1.5 Plot de Resultados Bayesianos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQAxOM5D08Hl"
   },
   "source": [
    "Llego la hora de visualizar los resultados obtenidos, para esto solo ejecute las siguientes celdas y observe lo que sucede :3. 쯈u칠 logra observar de los resultados?, 쯃a soluci칩n resulta trivial?\n",
    "\n",
    "En esta secci칩n esperamos que solo comenten con lo que logran visualizar de los dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1624645025761,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "id": "N5E2mNYXaafI",
    "outputId": "36f8a568-fb8d-4a2b-ff8e-651f206fbe53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower bounds aproximados:\n",
      "\n",
      "Top 20 post ordenador por el limite inferior:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#votos = votes[len(votes)-1]  esta no funciona\n",
    "#posteo = post[len(post)-1] esta no funciona\n",
    "votos = votes[18]\n",
    "posteo = post[18]\n",
    "print(\"lower bounds aproximados:\")\n",
    "posterior_mean, std_err = intervalos_numpy(votos[:, 0], votos[:, 1])\n",
    "lb = posterior_mean - std_err\n",
    "print(\"\\nTop 20 post ordenador por el limite inferior:\\n\")\n",
    "order = np.argsort(-lb)\n",
    "vote_post = {'Votos (+)':votos[order[:20], 0], 'Votos (-)':votos[order[:20], 1] ,'Post':np.array(posteo)[order[:20]], 'url': np.array(url[18])[order[:20]]}\n",
    "df = pd.DataFrame(data=vote_post)\n",
    "ordered_post = df.Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1753,
     "status": "ok",
     "timestamp": 1624645046704,
     "user": {
      "displayName": "IGNACIO ALEJANDRO MEZA",
      "photoUrl": "",
      "userId": "17011121633069169364"
     },
     "user_tz": 240
    },
    "id": "ZZ-AY2XTuLa_",
    "outputId": "5e363e6a-701b-4c2e-eb51-f082a8c6d492"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-f8cd58ca3582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mr_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_dic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mposterior_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std_err'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstd_err\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'post'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mordered_post\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m fig = px.scatter(df, x=\"mean\", y=\"post\",\n\u001b[0;32m      5\u001b[0m                  error_x=\"std_err\")\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "r_order = order[::-1][-20:]\n",
    "data_dic = {'mean':posterior_mean[r_order], 'std_err':std_err[r_order], 'post':ordered_post[::-1]}\n",
    "df = pd.DataFrame(data=data_dic)\n",
    "fig = px.scatter(df, x=\"mean\", y=\"post\",\n",
    "                 error_x=\"std_err\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szOjXLKA1Rif"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F83QdD61Pd1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "# Conclusi칩n\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los d칤as de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "enunciado_Laboratorio5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
